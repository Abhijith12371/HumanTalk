# ğŸ¹ Emotion Detection Bot

A Python-based Emotion Detection Bot that analyzes audio input and predicts the speaker's emotion using state-of-the-art transformer models and signal processing techniques.

## ğŸš€ Features

* ğŸ”Š Real-time audio recording and preprocessing
* ğŸ§  Transformer-based emotion classification using `transformers`, `peft`, and `sentence-transformers`
* ğŸ”‰ Noise reduction and audio feature extraction using `librosa` and `noisereduce`
* ğŸ§¾ Integration with `datasets` and `huggingface-hub` for dataset/model loading
* ğŸ“‚ Redis caching for fast inference
* ğŸ“ˆ Progress tracking with `tqdm`
* âœ… Unit-tested components using `unittest`

---

## ğŸ› ï¸ Installation

Create a virtual environment and install the required dependencies:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ“¦ Dependencies

Make sure your `requirements.txt` includes:

```
torch>=2.0.0
torchaudio>=2.0.0
transformers>=4.30.0
peft>=0.4.0
datasets>=2.0.0
sounddevice>=0.4.0
soundfile>=0.10.0
numpy>=1.20.0
redis>=4.0.0
sentence-transformers>=2.0.0
huggingface-hub>=0.0.0
pyyaml>=5.0.0
librosa>=0.9.0
noisereduce>=1.0.0
tqdm>=4.0.0
unittest>=1.0.0
```

---

## ğŸ¯ Usage

### 1. Record and Process Audio

```python
from audio_utils import record_audio, preprocess_audio

waveform = record_audio(duration=5)
clean_waveform = preprocess_audio(waveform)
```

### 2. Predict Emotion

```python
from emotion_detector import EmotionDetector

detector = EmotionDetector()
emotion = detector.predict(clean_waveform)
print(f"Detected Emotion: {emotion}")
```

---

## ğŸ¤ª Testing

Run unit tests:

```bash
python -m unittest discover tests/
```

---

## ğŸ§  Model Details

The bot uses a fine-tuned transformer model (like `facebook/wav2vec2-base-960h`) or sentence embeddings with `sentence-transformers` to detect emotions such as:

* ğŸ˜ƒ Happy
* ğŸ˜¢ Sad
* ğŸ˜¡ Angry
* ğŸ˜¨ Fear
* ğŸ˜ Neutral

---

## ğŸ”§ Project Structure

```
emotion-bot/
â”‚
â”œâ”€â”€ audio_utils.py            # Audio recording & preprocessing
â”œâ”€â”€ emotion_detector.py       # Inference logic using Hugging Face
â”œâ”€â”€ config.yaml               # Config for model and parameters
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ tests/
    â”œâ”€â”€ test_audio_utils.py
    â””â”€â”€ test_emotion_detector.py
```

---

## ğŸ§  Future Improvements

* Integrate facial emotion detection via webcam
* Add multilingual emotion detection
* Deploy as a web app or chatbot

---



## ğŸ“„ License

This project is licensed under the MIT License.
